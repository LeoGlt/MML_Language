library(utils)
library(dplyr)
library(caret)
library(e1071)
library(rpart)
library(questionr)library(rjson)
data <- read.csv('Spotify.csv', sep=';')
y <-"like"
X <- c('NumId','acousticness','danceability','duration','energy','instrumentalness','key','liveness','loudness','mode','speechiness','tempo','time_signature','valence')
formula = as.formula(paste(y, paste(X,collapse = " + "), sep = " ~ "))
results = list()
fit.control <- trainControl(method = "cv", number = 5)
results[[1]] = list(model=c(), output=list())
results[[1]]$model = "Decision tree"
clf = train(formula = formula,data = dataTrain, method = "rpart",control = (maxdepth = 1),parms = list(split ="gini", trControl = fit.control))
y_pred = predict(clf, dataTest, type = "class")
mat_conf <- table(y_pred,unlist(dataTest %>% select(y)))
accuracy = sum(diag(mat_conf))/sum(mat_conf)
results[[1]]$output[[1]] = list(metric = "accuracy", value = accuracy)
recall = mat_conf[2,2]/sum(mat_conf[,2])
results[[1]]$output[[2]] = list(metric = "recall", value = recall)
precision = mat_conf[2,2]/sum(mat_conf[2,])
results[[1]]$output[[3]] = list(metric = "precision", value = precision)
precision = mat_conf[2,2]/sum(mat_conf[2,])
recall = mat_conf[2,2]/sum(mat_conf[,2])
F1 = 2*precision*recall/(precision+recall)
results[[1]]$output[[4]] = list(metric = "f1 score", value = F1)
 first_row = mat_conf[1,1] / (mat_conf[1,1] + mat_conf[1,2])  
 second_row <- mat_conf[2,2] / (mat_conf[2,1] + mat_conf[2,2])  
 balanced_accuracy = (first_row + second_row)/2
results[[1]]$output[[5]] = list(metric = "balanced accuracy", value = balanced_accuracy)
results[[2]] = list(model=c(), output=list())
results[[2]]$model = "SVM"
clf = train(gamma=auto,C=1, kernel = "rbf", data = dataTrain, trControl = fit.control)
y_pred=predict(clf,dataTest, type = "class")
mat_conf <- table(y_pred,unlist(dataTest %>% select(y)))
accuracy = sum(diag(mat_conf))/sum(mat_conf)
results[[2]]$output[[1]] = list(metric = "accuracy", value = accuracy)
recall = mat_conf[2,2]/sum(mat_conf[,2])
results[[2]]$output[[2]] = list(metric = "recall", value = recall)
precision = mat_conf[2,2]/sum(mat_conf[2,])
results[[2]]$output[[3]] = list(metric = "precision", value = precision)
precision = mat_conf[2,2]/sum(mat_conf[2,])
recall = mat_conf[2,2]/sum(mat_conf[,2])
F1 = 2*precision*recall/(precision+recall)
results[[2]]$output[[4]] = list(metric = "f1 score", value = F1)
 first_row = mat_conf[1,1] / (mat_conf[1,1] + mat_conf[1,2])  
 second_row <- mat_conf[2,2] / (mat_conf[2,1] + mat_conf[2,2])  
 balanced_accuracy = (first_row + second_row)/2
results[[2]]$output[[5]] = list(metric = "balanced accuracy", value = balanced_accuracy)
results[[3]] = list(model=c(), output=list())
results[[3]]$model = "Logistic Regression"
clf = train(formula, data = dataTrain, method = "glm", trControl = fit.control)
y_pred=predict(clf,type = "response", newdata = dataTest)
mat_conf <- table(y_pred,unlist(dataTest %>% select(y)))
accuracy = sum(diag(mat_conf))/sum(mat_conf)
results[[3]]$output[[1]] = list(metric = "accuracy", value = accuracy)
recall = mat_conf[2,2]/sum(mat_conf[,2])
results[[3]]$output[[2]] = list(metric = "recall", value = recall)
precision = mat_conf[2,2]/sum(mat_conf[2,])
results[[3]]$output[[3]] = list(metric = "precision", value = precision)
precision = mat_conf[2,2]/sum(mat_conf[2,])
recall = mat_conf[2,2]/sum(mat_conf[,2])
F1 = 2*precision*recall/(precision+recall)
results[[3]]$output[[4]] = list(metric = "f1 score", value = F1)
 first_row = mat_conf[1,1] / (mat_conf[1,1] + mat_conf[1,2])  
 second_row <- mat_conf[2,2] / (mat_conf[2,1] + mat_conf[2,2])  
 balanced_accuracy = (first_row + second_row)/2
results[[3]]$output[[5]] = list(metric = "balanced accuracy", value = balanced_accuracy)
mat_conf <- table(y_pred,unlist(dataTest %>% select(y)))
print(toJSON(results))
